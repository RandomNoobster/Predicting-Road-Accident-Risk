{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91da1af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Notebook setup\n",
    "# ============================================================\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from util import util\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# ============================================================\n",
    "# WP1: Data & Baseline (Student A)\n",
    "# ============================================================\n",
    "\n",
    "# 1. Load Data\n",
    "# We assume the file is downloaded as per 'Methods and Tools' setup\n",
    "data_path = '../data/playground-series-s5e10/train.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Target is the numerical 'accident_risk'\n",
    "target_col = 'accident_risk'\n",
    "X = data.drop(columns=['id', target_col])\n",
    "y = data[target_col]\n",
    "\n",
    "# 2. Preprocessing\n",
    "# From \"Biomedical Data Analysis\": Handling mixed types\n",
    "num_cols = X.select_dtypes(include=['number']).columns\n",
    "cat_cols = X.select_dtypes(include=['object', 'bool']).columns # bool fits here too\n",
    "\n",
    "# One-hot encoding for categoricals (urban/rural, rainy/clear)\n",
    "X_encoded = pd.get_dummies(X, columns=cat_cols, drop_first=True)\n",
    "\n",
    "# Split Training and Validation\n",
    "# From \"Anomaly Detection\": Standard split to validate generalization\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scaling\n",
    "# From \"Non-Linear Models\" (Slide: NNs and Standardization):\n",
    "# Lasso requires standardized features to penalize weights fairly.\n",
    "scaler = StandardScaler()\n",
    "X_train_s = X_train.copy()\n",
    "X_val_s = X_val.copy()\n",
    "X_train_s[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "X_val_s[num_cols] = scaler.transform(X_val[num_cols])\n",
    "\n",
    "# 3. Lasso Baseline\n",
    "# From \"Non-Linear Models\" (Slide: Lasso):\n",
    "# \"The Lasso weights are sparse, i.e. only a few attributes will have impact\"\n",
    "print(\"Training Lasso Baseline...\")\n",
    "lasso = Lasso(alpha=0.001) # Low alpha since we have few features\n",
    "lasso.fit(X_train_s, y_train)\n",
    "\n",
    "# Evaluation\n",
    "pred_lasso = lasso.predict(X_val_s)\n",
    "rmse_lasso = np.sqrt(mean_squared_error(y_val, pred_lasso))\n",
    "print(f\"Baseline Lasso RMSE: {rmse_lasso:.4f}\")\n",
    "\n",
    "# From \"Non-Linear Models\": Inspecting weights to find correlates\n",
    "coeffs = pd.Series(lasso.coef_, index=X_train.columns)\n",
    "coeffs[coeffs.abs() > 0].sort_values().plot(kind='barh', figsize=(10, 6))\n",
    "plt.title(\"Lasso Coefficients (Linear Drivers of Risk)\")\n",
    "plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# WP2: Advanced Modeling (Student B)\n",
    "# ============================================================\n",
    "\n",
    "# 1. XGBoost Regressor\n",
    "# From \"Non-Linear Models\" (Slide: Gradient Boosted Trees Model):\n",
    "# We use GBT to capture non-linearities (e.g. speed_limit * curvature interactions)\n",
    "print(\"\\nTraining XGBoost...\")\n",
    "model = xgb.XGBRegressor(\n",
    "    n_estimators=500, \n",
    "    max_depth=5, \n",
    "    learning_rate=0.05, \n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred_xgb = model.predict(X_val)\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_val, pred_xgb))\n",
    "print(f\"XGBoost RMSE: {rmse_xgb:.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# WP3: Explainability & Business Evaluation (Student C)\n",
    "# ============================================================\n",
    "\n",
    "# 1. SHAP Analysis\n",
    "# From \"Additive Feature Attribution\"\n",
    "# Explaining specific risk factors for the test set\n",
    "print(\"\\nCalculating SHAP values...\")\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_val)\n",
    "\n",
    "plt.figure()\n",
    "shap.summary_plot(shap_values, X_val)\n",
    "\n",
    "# 2. Asymmetric Cost Evaluation\n",
    "# From \"RUL Prediction\" (Slide: Cost Model):\n",
    "# \"A failure costs C units more than maintenance\".\n",
    "# In our case: Underestimating risk (Safety Hazard) costs more than Overestimating (Caution).\n",
    "\n",
    "def asymmetric_risk_loss(y_true, y_pred, penalty_underestimate=5.0):\n",
    "    \"\"\"\n",
    "    Custom metric for 'AI in Industry'. \n",
    "    If y_true > y_pred (Underestimate), we penalize by factor 'penalty_underestimate'.\n",
    "    \"\"\"\n",
    "    diff = y_pred - y_true\n",
    "    # Where diff < 0 (Underestimate), multiply error by penalty\n",
    "    # Where diff > 0 (Overestimate), keep error as is\n",
    "    weighted_diff = np.where(diff < 0, diff * penalty_underestimate, diff)\n",
    "    return np.mean(np.abs(weighted_diff))\n",
    "\n",
    "# Compare models using this \"Industrial\" metric\n",
    "cost_lasso = asymmetric_risk_loss(y_val, pred_lasso)\n",
    "cost_xgb = asymmetric_risk_loss(y_val, pred_xgb)\n",
    "\n",
    "print(f\"\\n--- Industrial Evaluation (Safety Weighted Cost) ---\")\n",
    "print(f\"Lasso Cost: {cost_lasso:.4f}\")\n",
    "print(f\"XGBoost Cost: {cost_xgb:.4f}\")\n",
    "print(f\"XGBoost Improvement: {((cost_lasso - cost_xgb)/cost_lasso)*100:.1f}%\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
